{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical Flow\n",
    "**原理**： 利用图像序列中像素在时间域上的变化以及相邻帧之间的相关性来找到上一帧与当前帧之间存在的对应关系，从而计算出相邻帧之间物体运动信息的一种方法。     \n",
    "一般由两个部分组成，一个是**收缩部分**， 由卷积层组成，用于深度的提取两个图片的一些特征，一个是**扩大层**，把光流恢复到高像素。    \n",
    "## 1收缩部分网络结构    \n",
    "### 1.1 FlownetSimple    \n",
    "将输入的图片叠加在一起，通过一个比较普通的 网络结构，自动决定如何从这一图片中提取光流信息。如下图：    \n",
    "    <img src=\"img/flownetsimple.png\">\n",
    "### 1.2 FlowNetCorr      \n",
    "先独立的提取两图片特征，再在高层次中把这两个特征混合在一起，如下图：    \n",
    "    <img src=\"img/flownetcorr.png\">\n",
    "观察相连的那一层，是相互卷积，所以没有可以训练的权重（*相连那一层的连接方式有疑问*）   \n",
    "\n",
    "## 2 放大部分网络结构    \n",
    "每个基层，由unpooling和一个卷积构成,输出得到feature map，然后每一步与上一步的光流预测和收缩部分对应的feature map结合起来。    \n",
    "    <img src=\"img/enlarge.png\">    \n",
    "\n",
    "\n",
    "** 关于输出，应该是一个2d的张量，其中每个向量表示对应点的移动放方向。**\n",
    "\n",
    "---\n",
    "    \n",
    "# Regions with CNN(目标检测）    \n",
    "1 先用selective search选取n个候选框，然后scale到相同的size，如256x256,\n",
    "2 利用预训练好的CNN， 处理候选框输入256x256xn\n",
    "3 CNN输出到全连接层，得到1000xn\n",
    "4 将上一步输出到m个SVM，m表示需要识别的目标数量，得到每一个候选框所属目标概率，然后对每个目标，选取概率最高的候选框\n",
    "5 对该候选框在第3步的输出利用岭回归进行调整，其loss值为与对应正确输入的mean square\n",
    "\n",
    "# Fast-RCNN\n",
    "与RCNN 的不同之处\n",
    "1 不用SVM选择，直接对第三步的全连接输出\n",
    "2 对第三步的全连接输出，计算两个loss，一个为所有目标向量是否正确（即对某一目标长度为n的向量与正确的one-hot向量计算softmax cross-entropy loss),第二个为调整候选区域的regression loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
